<!DOCTYPE html>
<html>
<head>

  <meta charset="utf-8">
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@2.0.0/dist/tf.min.js"></script>
</head>

<body>
  <div class="container">
    <p id="demo"></p>
    <p id="demo2"></p>
    <canvas class="output_canvas"  width="1280px" height="720px">
      <video class="input_video"></video>
    </canvas>
  </div>
</body>
</html>



<script type="module">

  const model = await tf.loadLayersModel('./model.json')

  const videoElement = document.getElementsByClassName('input_video')[0];
  const canvasElement = document.getElementsByClassName('output_canvas')[0];
  const canvasCtx = canvasElement.getContext('2d');

  // DEFINITIONS FOR MODEL
  const classconversion = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H',
                   8: 'I', 9: 'J', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O',
                   15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V',
                   22: 'W', 23: 'X', 24: 'Y', 25: 'Z', 26: 'del', 27: 'nothing', 28: 'space'}

  // ROLLING AVG VARIABLES
  const avg_of_frames = 5;
  var frame_averages = new Array(avg_of_frames);
  for (var i = 0; i < frame_averages.length; i++) {
    frame_averages[i] = new Array(42).fill(0);
  }
  var counter = 0;
  var rolling = new Array(42).fill(0);


  function Normalise(lms, height, width){
    //FIRST HAND ONLY
    var normalised_landmarks = new Array(42);

    var basex = lms[0][0].x * width;
    var basey = lms[0][0].y * height;
    var thumbx = lms[0][1].x * width;
    var thumby = lms[0][1].y * height;

    var scale_factor = (((thumbx - basex) ** 2) + ((thumby - basey) ** 2)) ** 0.5;

    for (let index = 0; index < lms[0].length; index++) {
      normalised_landmarks[index*2] = ( (lms[0][index].x * width) - basex) / scale_factor;
      normalised_landmarks[index*2+1] = ( (lms[0][index].y * height) - basey) / scale_factor;
    }

    return normalised_landmarks;
  }

  function indexOfMax(arr) {
    if (arr.length === 0) {
        return -1;
    }

    var max = arr[0];
    var maxIndex = 0;

    for (var i = 1; i < arr.length; i++) {
        if (arr[i] > max) {
            maxIndex = i;
            max = arr[i];
        }
    }

    return maxIndex;
}


  function onResults(results) {
    canvasCtx.save();
    canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
    canvasCtx.drawImage(
        results.image, 0, 0, canvasElement.width, canvasElement.height);

    if (results.multiHandLandmarks) {

      var normalised_landmarks = Normalise(results.multiHandLandmarks, canvasElement.height, canvasElement.width);
      var format_lms = tf.stack(normalised_landmarks).reshape([1,42,1]);
      const prediction = model.predict(format_lms);

      // ROLLING AVG START
      frame_averages[counter] = prediction.arraySync()[0];

      for (var j = 0; j < avg_of_frames; j ++){
        for (var p = 0; p < 42; p ++) {
          rolling[p] = rolling[p] + frame_averages[j][p];
        }
      }

      var index = indexOfMax(rolling);
      var letter = classconversion[index];

      counter = counter + 1;
      if (counter == avg_of_frames) {
        counter = 0;
      }

      document.getElementById("demo2").innerHTML = letter;

      // ROLLING AVG END



      //WORKING PROTOTYPE -- DO NOT DEL!!!!!!!!!!!!
      // var index = indexOfMax(prediction.arraySync()[0]);
      //
      // var test = classconversion[index];
      //
      // document.getElementById("demo2").innerHTML = test;


      //mediapipe drawings
      for (let index = 0; index < results.multiHandLandmarks.length; index++) {

        const classification = results.multiHandedness[index];
        const isRightHand = classification.label === 'Right';
        const landmarks = results.multiHandLandmarks[index];

        drawConnectors(
            canvasCtx, landmarks, HAND_CONNECTIONS,
            {color: isRightHand ? '#00ff00' : '#FF0000'}),

        drawLandmarks(canvasCtx, landmarks, {
          color: isRightHand ? '#00FF00' : '#FF0000',
          fillColor: isRightHand ? '#FF0000' : '#00FF00',
          radius: (x) => {
            return lerp(x.from.z, -0.15, .1, 10, 1);
          }
        });
      }
    }
    canvasCtx.restore();
  }


  const hands = new Hands({locateFile: (file) => {
    return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
  }});


  hands.setOptions({
    maxNumHands: 2,
    minDetectionConfidence: 0.7,
    minTrackingConfidence: 0.5
  });


  hands.onResults(onResults);


  const camera = new Camera(videoElement, {
    onFrame: async () => {
      await hands.send({image: videoElement});
    },
    width: 1920,
    height: 1080
  });


  camera.start();


</script>